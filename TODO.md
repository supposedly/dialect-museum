# TODO

## After rewriting Capture
* try not to use so many classes
* ~~rename new Capture class to something fitting (Manager)~~
* ~~Convert layers to indices in Capture so that each Tracker doesn't do it individually~~
* ~~be smarter about invalidating dependencies, use the `where` param of rules~~
* update MatchOne (and other classes that forward to it) to let a custom arg (or args) be passed to matched functions
  * this is useful for e.g. checking that next and prev have the same value -- can't do that easily without a function
* Fix MatchOne so that empty objects always match instead of never matching
* turn TrackerHistory into a linked list...? don't actually need indices for it i don't think

## Before rewriting capture

* Make everything less hardcoded:
  * Initialize verb prefixes with just their literal pronoun value (like 3ms or whatever) to be .expanded() into actual segments way later, in the transformer stage
  * Have initializers take an alphabet instead of using a global one
* Make verb suffixes actual suffixes in the alphabet (no `{symbol}` key needed for grammar, just put them in the alphabet) -- so for example `-uu` being its own suffix
  thing allows it to be easily expanded into `Ù€ÙˆØ§` in the Arabic script
  (like `` word.capture.underlying.suffix({value: `verb-plural`}).promote({into: [word.abc.surface.w, word.abc.surface.alif]}) ``... or heck maybe you could even
  jank the normal `+` and `c/C` suffixes onto verbs, like `c` is already being used in the past tense? if so then heck
  `` word.capture.underlying.suffix({value: `plural`}).promote({into: [word.abc.surface.w, word.abc.surface.alif], where: {wordType: objType.verb}}) ``)
* finish verb initializer (man)
    * ~~collapse `long vowel.long vowel` sequences (generated by conjugating a final-weak verb) into just the second vowel~~
    * ~~implement nfa3al-i fta3al-i and nfa3al-a fta3al-a forms (or maybe **nfi3il/fti3il & nfa3al/fta3al** even tho that breaks the pattern of using 3ms.pst)~~
    * ~~make sure f3ii and f3aa imperatives are in place~~
    * ~~add all of fa3yit, fi3yit, fi3it, fa3it~~
    * ~~make sure parseWord is upholding the stress in stuff like `` $`+nFi -3iL` ``~~
    * Figure out how to vary between tinsaani\~tinsiini (both for masc), 2it7addaak\~2it7addiik, etc.
* ~~delete stAf3al from verb and pp (probably)~~
* ~~account for final-vowel-plus-suffix combos like mfa33aa+c == mfa33aayc in pp's initializer~~
* ~~add `(2af3al ...)` tag to grammar~~
* ~~add `(taf3il ...)` tag to grammar (takes a root and generates $`t.a/i.${$F} ${$3}.ii.${$L}`) **plus t.a/i.F.3.i.y.c \~ t.a/i.F.3.aa.y.c**~~
* ~~Add `(ctx ...)` tag to grammar, e.g. `(ctx [proper noun] [tense final vowel] jOni)` or `(ctx [self] s*arr~1ms)`, `ma (ctx [stress] (verb [3ms] [u] [pst] q{w}l|2fs))`~~
* Add `(fa3a3iil ...)` tag to grammar (expands to `fa3a3iil, f3aa3iil`)
* Add `(7arf ...)` tag to grammar, e.g. `(7arf b)` => `bii, bi, b` or something & `(7arf l)` => `la, l, y`
* implement the other tags smh
* ~~change mu- to mi- in pp~~
* ~~turn pronoun objects' boolean attrs into methods~~
* ~~add postTransform to parseWord and figure out a way to handle combinations...~~
* Make augmenting a distinct step and allow multiple augmentations (no reason why it couldn't happen!)
* ~~Add metadata to consonants: place, manner, voicing **(grouped by articulator instead of place)**~~
* ~~Update style: enforce commas on the last element of multiline lists, enforce curly-internal spaces only for blocks and not objects~~
* ~~Create a module that exports string tags to map certain strings to numbers (basically what's currently in phoneme-properties.js) **(enums)**~~
* ~~a/i is weird and shouldn't exist... BUT it's useful on the backend side of things because it helps me avoid duplicating stuff. As a compromise between
  **obliterating it** and letting it fester and make everything gross, just find a way to make sure that anything containing a/i is always expanded out
  into two separate options (one with a, one with i) before it reaches the transformer stage~~
* ~~Remove meta.t attribute from feminine suffix~~
* deal with emphatic Z from Øµ vs. emphatic Z from Ø¸
* add nisbe (with the symbol % lol) to grammar
* remove schwa from alphabet & grammar
  * can't figure out how to replace schwa, maybe one of these options:
    * in Word (before Capture is even a thing), add nulls or noschwas between all consonant pairs in order to make space for future possible schwas (including ones that aren't originally necessary but arise out of vowel-deletion)
    * or: figure out a way to capture the space **between** segments with a Capture.between() method... hmph
  * either figure out how to let noschwa be added between syllables (as in CVC_Ci...) or remove it too
    * if removed, replace it with a specific transform rule that allows schwa not to be inserted between two consonants AB where (1) A's articulator is within distance 1 of B's, and (2) A is more sonorous than B; this covers most cases like Ø¥Ù†ØªØŒ Ø§Ù„Ù‡Ù†Ø¯ØŒ Ø¯Ø³ØªØŒ ÙŠØ³ØªÙ†Ø§ÙˆÙ„, etc... even tho it doesn't allow special-casing ÙƒØ±ÙØ³ and Ù†ÙØ³  (maybe those are iffy anyway)
* figure out some kind of pre-handler stage where suffixes (`%` nisbe, `c` fsg, `C` fpl, `=` dual, `+` plural) and verb-conjugation prefixes are expanded into normal letters... in a way that both lets them be toggled and also lets their individual letters be toggled/behave as normal parts of the word
* probably remove the index-caching stuff from Capture, schwa-insertion and the pre-handler thingy makes it tough to deal with (can always try to work out a similar efficiency solution later)
* NO MORE TRANSFORM FUNCS!!!
  * instead of a method chain like `capture.segment().handle(({envParam}) => { if (envParam === value) return [bruh, bruv]; })`,
    make it `transform.segment().into([bruh, bruv]).where({envParam: value}).because(reason)`
    or `transform.segment()({into: [bruh, bruv], where: {envParam: value}, because: reason})`
    * this means transforms and deps are no longer black boxes, making them easier to analyze and modify programmatically
    * it also forces transforms to only go one-to-one, making it easy to tie a specific reason to each transform
  * this obviates the whole overengineered (even if kinda cool) param-grabby thingy ðŸ˜”
  * the `reason` should apply to the transformation and all of its options, not individual options like I was originally thinking  
    (e.g. instead of "some people pronounce alif as O around emphatics" "some people pronounce alif as A around emphatics" just do "emphatics change the pronunciation of nearby alifs. some people round to O etc")
  * possibly do `{bruh: 0.5, bruv: 0.5}` instead of an array to handle probabilistic outputs
* Split `ipa-phonemic` into a few modules: `common` for utils and classes (might have submodules for diff classes), `iconophonemic`, `phonemic`, `phonetic`, and maybe `random`
    * `iconophonemic`: for scripts that will have fixed iconic symbols for Ø© and stuff, and also adhere to archiphonemes like `aa` and `ay/aw`; can maybe specify which phoneme groups should be abstracted over in that way (eg i want -iin to be -iin instead of a symbol, and if not that then the transformer will maybe do something like `iconophonemicAlphabet.iin.contracted || iconophonemicAlphabet.iin.default, iconophonemicAlphabet.iin.full || iconophonemicAlphabet.iin.default, etc`
    * `phonemic`: for scripts that are based on phonemes and have none of those icons^, so this transformer will translate `abc.c` into `[abc.e, abc.i]` or something and then surface it as whichever one of those two would surface -- instead of leaving it as `abc.c` and surfacing it as `iconophonemicAlphabet.c.lowered/raised || iconophonemicAlphabet.c.default`
    * `phonetic`: this one is gonna be a pain in the neck and i'm probably gonna put it off
    * `random`: not exactly sure how this will work but it's for 3arabizi and stuff where vowels might just disappear no matter what they are... also geminates need to be only randomly observed
* Maybe let alphabets have transformers of their own, eg a meme ->katakana transformer could first do romaji like `abc.t abc.u` -> `"tu"` and then have the `"tu"` be processed into `"ãƒ„"`
* for the fabled U(n)I(corn): when you click on a letter in a word it gives you both the list of options and the probability slider for each option. the sliders affect all instances of that segment in that environment, not just that particular segment; correspondingly, you can click on any one of the options to test it out even if its slider value is at 0% probability
  * also, touching a slider causes it to reroll for all words, overwriting/forgetting your particular choice for that word

### Random whiteboardstorming

* UI and transformer stuff  
  ![image](https://user-images.githubusercontent.com/32081933/133937172-7fca4a2f-55fb-4dd8-b1e7-2b8e6615eace.png)  
  There's another newer note to the left giving `abc.funcs = {delete(letter), stress(vowel), stressWord(word), nasalize(word), emphaticize(letter)}` and noting that `nasalize` should maybe get the whole word so it can match it to an alternative spelling if necessary (e.g. `lOsyON"` should prob match `lotion` in 3arabizi, not `losyon`)

### Roadmap for getting the Capture rewrite underway and beyond
1. ~~fix prefix and pronoun-initializer and whatever else to just return objects like {type: prefix, meta: {person: etc, gender: etc, number; etc}}~~
2. ~~then fix pp-initializer and verb-initializer so that they use that type of return value instead of literal segments~~
3. then go into classes and fix the Word constructor so that it doesn't treat prefixes as anything special (since now they'll just be a normal
   segment of the word)
5. ~~then possibly do the same thing for augmentations idk what do i know~~
6. then add a this.capture attribute to Word in the constructor so that you can do `word.capture.underlying.segment()` or `word.capture.surface.segment()` or etc
7. the ultimate idea is to have prefixes (and maybe augmentations) all handled by .expand()
8. on that topic, replace the `handler =>` thingy in Capture with three methods: .transform(), .expand(), .promote()  
   where transform transforms, expand transforms into multiple thingies, promote goes up a level in the alphabet hierarchy
10. then update all the indexing to be able to recurse to handle the result of .expand()
11. then also replace extractDeps and stuff with a simple method that checks the `{where}` key passed to those three methods
12. then update the dep-handling to be more specific about only looking at the exact deps requested (since we can inspect
    them now unlike with black-box functions)
14. then hopefully figure out a way to handle schwa-insertion...
15. then work on creating alphabets
16. then have nothing but fun with the frontend
17. also replace all .map().flat() with .flatMap() at some point
